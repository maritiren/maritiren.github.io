[{"content":" Heyyo This section contains whatever I think is useful when I do computer stuff.\n","date":null,"permalink":"/posts/","section":"Blog posts","summary":"","title":"Blog posts"},{"content":"","date":null,"permalink":"/tags/ci/","section":"Tags","summary":"","title":"CI"},{"content":"","date":null,"permalink":"/tags/iac-scan/","section":"Tags","summary":"","title":"IaC Scan"},{"content":"","date":null,"permalink":"/tags/pipeline/","section":"Tags","summary":"","title":"Pipeline"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/trivy/","section":"Tags","summary":"","title":"Trivy"},{"content":"I am currently working with automated security testing to get control of the known vulnerabilities in our applications. As part of this, I am scanning a Kubernetes cluster and it\u0026rsquo;s images, as well as application code. We want to cover the whole width, not only application code. Now, we look at a Infrastructure as Code (IaC) scanning tool, Trivy.\nRead more about Trivy in my other post.\nDebugging #go not scanned properly #Some pipelines got 44 findings, while other\u0026rsquo;s had none. By looking at the pipeline logs, we figured that it wasn\u0026rsquo;t detected properly that this was a Go repo.\nRunning the commands locally also yields no findings (except one that is ignored with .trivyignore). With debug on, I found that Trivy is Skipping vulnerability scan as no version is detected for the package name=\u0026quot;my.project.com/main/module\u0026quot;.\n2024-10-03T11:37:58+02:00\tINFO\t[gomod] Detecting vulnerabilities... 2024-10-03T11:37:58+02:00\tDEBUG\t[gomod] Scanning packages for vulnerabilities\tfile_path=\u0026#34;go.mod\u0026#34; 2024-10-03T11:37:58+02:00\tDEBUG\t[gomod] Skipping vulnerability scan as no version is detected for the package name=\u0026#34;my.project.com/main/module\u0026#34; Possibilitites:\nSet an older version? An idea from this issue stating it stopped working after version 0.45.1 Maybe the cache isn\u0026rsquo;t working properly Trying an older version:\ndocker run -v $PWD:/src --workdir /src aquasec/trivy:0.45.0 -d fs . --scanners config,vuln,secret --no-progress ... 2024-10-06T15:12:43.971Z\tDEBUG\tGOPATH (/root/go/pkg/mod) not found. Need \u0026#39;go mod download\u0026#39; to fill licenses and dependency relationships 2024-10-06T15:12:43.979Z\tDEBUG\tOS is not detected. 2024-10-06T15:12:43.979Z\tDEBUG\tDetected OS: unknown 2024-10-06T15:12:43.979Z\tINFO\tNumber of language-specific files: 1 2024-10-06T15:12:43.979Z\tINFO\tDetecting gomod vulnerabilities... 2024-10-06T15:12:43.979Z\tDEBUG\tDetecting library vulnerabilities, type: gomod, path: go.mod ... Dockerfile (dockerfile) ======================= Tests: 26 (SUCCESSES: 25, FAILURES: 1, EXCEPTIONS: 0) Failures: 1 (UNKNOWN: 0, LOW: 1, MEDIUM: 0, HIGH: 0, CRITICAL: 0) ... .trivycache/policy/content/commands/kubernetes/containerNetworkInterfaceFilePermissions.yaml (secrets) ====================================================================================================== Total: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 1 Trying the newest version at this time, 0.56.0:\ndocker run -v $PWD:/src --workdir /src aquasec/trivy:0.56.0 -d fs . --scanners misconfig,vuln,secret --no-progress We cloned the Trivy repo and logged to check whether the packages has been scanned. On version 0.56.0, they are scanned even though the main module gets the message Skipping vulnerability scan as no version is detected for the package name=\u0026quot;my.project.com/main/module\u0026quot;. However, when the scan finds all modules, it says Number of language-specific files: N, where N is more than just one.. This needs more investigation.\nFound here in the Trivy code.\nI think this might be a GitLab Runner issue. Perhaps the GitLab Runner cache. All local tests with and without Trivy cache is working as supposed to. Perhaps not, though. Still looking into it.\nThe results were inconsistent in GitLab. After clearing the pipeline cache, the pipeline findings are more consistent. However, they are not the same locally and in pipeline. Seems like due to recursive dependencies are added in the pipeline and not locally. Locally, I don\u0026rsquo;t have the The \u0026ldquo;very\u0026rdquo; old results that had bout 35-44 findings, I think is because of GitLab Runner cache of the Go path.\nRegarding the recursive dependencies, I see that the scan fetches packages from $HOME/go/pkg/mod. After running go mod download, I have other dependencies locally than what is scanned in the pipeline. That might cause different results.\nI decided to try with GitHub Actions to see if it acts weird there as well.\nThe Trivy GH Action uses Trivy version 0.53.0 By default, it doesn\u0026rsquo;t log the output from the Trivy run Husk:\nSjekk om det er Go cache Resources # https://www.aquasec.com/blog/devsecops-with-trivy-github-actions/ https://github.com/aquasecurity/trivy/discussions/5744 Trivy GitHub discussion: Intermittent missing vulnerabilities from Trivy 0.55.0 #7585 ","date":null,"permalink":"/posts/trivy-pipeline/","section":"Blog posts","summary":"","title":"Trivy in CI Pipeline"},{"content":" Welcome to my notebook! I realized I need to put my final notes somewhere. When I go back to something I've taken notes about, I don't remember how finished they really are. If I publish them publicly, they have to be somewhat done! ^_^ ","date":null,"permalink":"/","section":"Welcome to my notes! ðŸŽ‰","summary":"","title":"Welcome to my notes! ðŸŽ‰"},{"content":"","date":null,"permalink":"/tags/k8s/","section":"Tags","summary":"","title":"K8s"},{"content":"I am currently working with automated security testing to get control of the known vulnerabilities in our applications. As part of this, I am scanning a Kubernetes cluster and it\u0026rsquo;s images, as well as application code. We want to cover the whole width, not only application code. Now, we look at a Infrastructure as Code (IaC) scanning tool, Trivy.\nRead more about Trivy in my other post.\nTrivy has a Kubernetes operator called Trivy Operator. Advantages with using the Trivy Operator are (source) :\nTrivy Operator does background scans continuously in the cluster Trivy CLI cannot detect changes of any resources running inside the cluster Trivy Operator allows integrating with tools that can consume Kubernetes manifests as it produces reports that are CRDs Kubernetes best practice is to push information from within the cluster to tools outside rather than letting the tools pull data from the outside One downside which is not in our scope, but is worth mentioning, is that the Trivy Operator does not scan prior to deployment. Hence, it can not be used as a quality control or quality gate. Therefore, you should still run Trivy CLI in your pipelines. Prereqs to follow this guide # Kind kubecm, strictly not necessary, but I like this tool! Helm Trivy An image that can be deployed to the cluster Info #The Trivy Operator continuously scans the Kubernetes cluster. From docs:\nThe Operator does this by watching Kubernetes for state changes and automatically triggering security scans in response. For example, a vulnerability scan is initiated when a new Pod is created. This way, users can find and view the risks that relate to different resources in a Kubernetes-native way.\nStep-by-step #\nSetup local cluster # Setup Flux with local registry OR setup a simple cluster\nkind create cluster Select local cluster (it is called kind-kind by default) with kubecm\nkubecm s kind-kind For a more realistic environment, run a deployment\nk apply -f ~/git/testing/flux-image-updates/clusters/my-cluster/podinfo/podinfo-deployment.yaml watch kubectl get pods (optional) push image to the local registry and create deployment for it\nTrivy needs images to scan, but there are probably already other images in your cluster. E.g. from Flux or others.\ndocker tag 0ac97f5bbbb5 localhost:5001/my-api:1.0.1 docker push localhost:5001/my-api:1.0.1 (optional) Check contents of registry\nFlux should automatically deploy new images when they get a new tag (according to the tag policy). To verify what\u0026rsquo;s in the registry, you can curl it.\nâœ— curl -X GET http://localhost:5001/v2/_catalog {\u0026#34;repositories\u0026#34;:[\u0026#34;my-api\u0026#34;,\u0026#34;hello-app\u0026#34;,\u0026#34;podinfo\u0026#34;]} **strong text** âœ— curl -X GET http://localhost:5001/v2/podinfo/tags/list {\u0026#34;name\u0026#34;:\u0026#34;podinfo\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;5.0.7\u0026#34;,\u0026#34;5.0.3\u0026#34;,\u0026#34;5.0.5\u0026#34;,\u0026#34;5.0.0\u0026#34;,\u0026#34;5.0.4\u0026#34;,\u0026#34;5.0.6\u0026#34;]} (optional) Test Trivy Operator locally #https://aquasecurity.github.io/trivy-operator/latest/\nI do this to get a better feeling of how Trivy works and how it should look in the cluster. You can install the Trivy Operator using a YAML manifest file, or as a Helm Chart. We will do the latter. Steps from the docs:\nOption 1: Install from traditional Helm Chart repository\nAdd the Aqua chart repository: helm repo add aqua https://aquasecurity.github.io/helm-charts/ helm repo update Install the Helm Chart: helm install trivy-operator aqua/trivy-operator \\ --namespace trivy-system \\ --create-namespace \\ --version 0.21.0 Installing the operator yields the following output:\nâœ— helm install trivy-operator aqua/trivy-operator \\ --namespace trivy-system \\ --create-namespace \\ --version 0.21.0 NAME: trivy-operator LAST DEPLOYED: Wed Mar 27 09:14:18 2024 NAMESPACE: trivy-system STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: You have installed Trivy Operator in the trivy-system namespace. It is configured to discover Kubernetes workloads and resources in all namespace(s). Inspect created VulnerabilityReports by: kubectl get vulnerabilityreports --all-namespaces -o wide Inspect created ConfigAuditReports by: kubectl get configauditreports --all-namespaces -o wide Inspect the work log of trivy-operator by: kubectl logs -n trivy-system deployment/trivy-operator Running these commands, we see that the operator is starting making reports. I am interested to see if the podinfo deployment has any reports.\nThe instructions above are from the \u0026ldquo;Home\u0026rdquo; page of the docs, while there are also more options in the Helm installation page.\nPlay with the in-cluster API #\u0026hellip; to get an overview of have the tool works. Is it even worth installing in the cluster?\nGet an overview #To get an overview of all findings, we can use the reports as shown in the output above:\nâœ— kubectl get vulnerabilityreports --all-namespaces -o wide NAMESPACE NAME REPOSITORY TAG SCANNER AGE CRITICAL HIGH MEDIUM LOW UNKNOWN flux-system replicaset-helm-controller-58d5cc6f5b-manager fluxcd/helm-controller v0.37.2 Trivy 92m 0 1 11 0 0 flux-system replicaset-image-automation-controller-654dc4897-manager fluxcd/image-automation-controller v0.37.0 Trivy 93m 0 1 8 0 0 flux-system replicaset-image-reflector-controller-8498c88d9-manager fluxcd/image-reflector-controller v0.31.1 Trivy 92m 0 0 9 0 0 ... âœ— kubectl get configauditreports --all-namespaces -o wide NAMESPACE NAME SCANNER AGE CRITICAL HIGH MEDIUM LOW default replicaset-podinfo-5d869859bd Trivy 94m 0 2 3 9 default service-kubernetes Trivy 94m 0 0 0 0 my-api replicaset-my-api-7cc565547 Trivy 94m 0 1 2 9 flux-system networkpolicy-allow-egress Trivy 94m 0 0 0 0 ... Dive deeper into findings #To checkout the findings, run the following commands\nâœ— kubectl describe vulnerabilityreport my-vulnerability-report -n default âœ— kubectl describe configauditreport my-configaudit-report -n default My pod had the following HIGH finding:\nCategory: Kubernetes Security Check Check ID: KSV118 Description: Security context controls the allocation of security parameters for the pod/container/volume, ensuring the appropriate level of protection. Relying on default security context may expose vulnerabilities to potential attacks that rely on privileged access. Messages: replicaset my-api-7cc565547 in my-api namespace is using the default security context, which allows root privileges Remediation: To enhance security, it is strongly recommended not to rely on the default security context. Instead, it is advisable to exp licitly define the required security parameters (such as runAsNonRoot, capabilities, readOnlyRootFilesystem, etc.) within the security context . Severity: HIGH Success: false Title: Default security context configured Setup Trivy Operator in production #Trivy Operator manifest files #https://aquasecurity.github.io/trivy/v0.50/tutorials/kubernetes/gitops/\nOkay, so I think this will give value. Especially in a scenario where Kubernetes is used for standard applications in an organisation. Then we have centralized image scanning and can report known vulnerabilities without the teams having to set up anything themselves.\nSo let\u0026rsquo;s look into how to add the Trivy Operator to a cluster in production.\n--- apiVersion: v1 kind: Namespace metadata: name: trivy-system --- apiVersion: source.toolkit.fluxcd.io/v1beta2 kind: HelmRepository metadata: name: trivy-operator namespace: flux-system spec: interval: 60m type: oci url: oci://ghcr.io/aquasecurity/helm-charts --- apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: trivy-operator namespace: trivy-system spec: chart: spec: chart: trivy-operator version: 0.21.0 sourceRef: kind: HelmRepository name: trivy-operator namespace: flux-system interval: 60m values: trivy: resources: limits: memory: 1500M # Default of ?? wasn\u0026#39;t enough, causing OOMKilled workload containers ignoreUnfixed: true operator: scanJobsConcurrentLimit: 2 # Default of 10 used too much RAM at once for Nodes, causing OOMkilled workload containers install: crds: CreateReplace createNamespace: false Configure Calico network policy #If you are using Calico or other network management tools and run the manifests above, you will most likely get the following error or something similar: unable to run trivy operator: failed getting configmap: trivy-operator: Get \u0026quot;https://10.0.0.1:443/api/v1/namespaces/trivy-system/configmaps/trivy-operator\u0026quot;: dial tcp 10.0.0.1:443: i/o timeout.\nThis means that you need to add a network policy. Trivy requires two network accesses:\nAccess to the K8s API Access to the vulnerability database Adhering to the principle of least privilege is quite hard here. In the network policy, only IP ranges can be set. Using Azure, one can set more tailored rules in front. However, those rules apply to the whole cluster, not one namespace or Kubernetes resource.\nHere is an example of a network policy for Calico to allow Trivy access to the K8s API:\n--- apiVersion: projectcalico.org/v3 kind: NetworkPolicy metadata: name: allow-trivy-operator-egress namespace: trivy-system spec: types: - Egress egress: - action: Allow # allow k8s API calls destination: services: name: kubernetes namespace: default - action: Allow # allow vulnerability database fetch destination: ports: - \u0026#34;443\u0026#34; nets: - 0.0.0.0/0 protocol: TCP To check the calico network policy when it has been applied:\ncalicoctl get networkpolicy allow-trivy-operator-egress -o yaml -n trivy-system --allow-version-mismatch Tolerate node taints #https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/\nIf your cluster has taints on nodes, you will see that the Trivy node collector isn\u0026rsquo;t running correctly. You can check by first finding the node collector name (list all resources in the namespace and you will have it), and then run kubectl describe on it. The events will show what is wrong, e.g. FailedScheduling with the message 0/7 nodes are available: 1 node(s) had untolerated taint .....\nk describe pod/node-collector-677f9fb5b8-jc6tw -n trivy-system Find the taints on the nodes in your cluster:\nâžœ ~ kubectl get nodes -o json | jq \u0026#39;.items[] | {name: .metadata.name, taints: .spec.taints}\u0026#39; Then you can add it to the HelmRelease as values. Note that it is not common pod tolerations you must configure, but tell the Trivy Operator through values.triyvOperator.scanJobTolerations which tolerations the node-collector pod should have.\nWhat happens when setting common tolerations Updating the tolerations, the node-collector pod didn\u0026rsquo;t get them applied, only the operator pod (checking with k describe pod/node-collector-some-id and same for pod/trivy-operator). I found an issue and deleted all files to reset, but it didn\u0026rsquo;t work. With some more research, I found that I must set the tolerations in the Helm values\n... values: trivy: ignoreUnfixed: true trivyOperator: scanJobTolerations: - key: \u0026#34;key1\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value1\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; In version 0.21.1, it was supported to add tolerations to NodeCollector. At that point, we started getting the same toleration error messages and the NodeCollector timed out. Looking at the HelmChart Artifact Hub, we fixed by adding tolerations to the node collector as well:\n... values: trivy: ignoreUnfixed: true trivyOperator: scanJobTolerations: - key: \u0026#34;key1\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value1\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; nodeCollector: - key: \u0026#34;key1\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value1\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; Done!\nAdd image scanning #Trivy scans images by default. If it is not working, make sure you allow network to fetch the vulnerability database, as well as allowing network to fetch images from your repository. Maybe this will help:\nhttps://aquasecurity.github.io/trivy-operator/latest/docs/vulnerability-scanning/private-registries/ https://aquasecurity.github.io/trivy-operator/v0.19.0/tutorials/private-registries/ Create reports #Coming soon maybe.\nGrafana dashboard #This was an easy fix, however it took a little time to figure out how to use the gnetId to create image through Terraform.\nI made a PR to the Trivy docs, so it should be documented now: https://aquasecurity.github.io/trivy-operator/v0.22.0/tutorials/grafana-dashboard/#using-the-grafana-helm-chart.\nUseful commands #\nTrivy Operator logs #From K8s:\nk logs -n trivy-system deployment/trivy-operator See all trivy-system resource (except from network policy):\nk get all -n trivy-system Flux reconcile logs #flux logs --namespace flux-system --since=1h -f flux logs --namespace flux-system --since=1h -f --kind=kustomization flux logs --namespace flux-system --since=1h -f --kind=kustomization --name=trivy-prereqs See new commits as they are detected:\nflux logs --namespace flux-system --since=1h -f --kind=gitrepository Delete/restart the operator #After doing lots of testing, you might want to delete the operator and install it again to see that a clean install works. You can do like this:\nkubectl delete all --all -n trivy-system Flux might automatically reinstall. If not, you can run\nflux reconcile kustomization flux-system --with-source -n flux-system or maybe\nflux reconcile helmrelease trivy-operator -n trivy-system Or just delete the files and see that the resources are gone, and then put them back.\nDelete all reports #kubectl delete exposedsecretreport --all --all-namespaces And then same for other reports, such as vulnerabilityreport.\nDebugging #SBOM decode error: failed to decode: multiple OS components are not supported #{ \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2024-04-08T10:04:45Z\u0026#34;, \u0026#34;logger\u0026#34;: \u0026#34;reconciler.scan job\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Scan job container\u0026#34;, \u0026#34;job\u0026#34;: \u0026#34;trivy-system/scan-vulnerabilityreport-6cccfb67dd\u0026#34;, \u0026#34;container\u0026#34;: \u0026#34;k8s-cluster\u0026#34;, \u0026#34;status.reason\u0026#34;: \u0026#34;Error\u0026#34;, \u0026#34;status.message\u0026#34;: \u0026#34;2024-04-08T10:04:37.564Z\\t\\u001b[31mFATAL\\u001b[0m\\tsbom scan error: scan error: scan failed: failed analysis: SBOM decode error: failed to decode: failed to decode components: multiple OS components are not supported\\n\u0026#34;, \u0026#34;stacktrace\u0026#34;: \u0026#34;github.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).completedContainers\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:353\\ngithub.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).SetupWithManager.(*ScanJobController).reconcileJobs.func1\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:80\\nsigs.k8s.io/controller-runtime/pkg/reconcile.Func.Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/reconcile/reconcile.go:113\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:119\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:316\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:266\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:227\u0026#34; } Haven\u0026rsquo;t looked into this yet.\nscan error: unable to initialize an image scanner: remote error (image fetch) #This problem is because GETing the URL provides a bad response.\n{ \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2024-04-23T03:07:55Z\u0026#34;, \u0026#34;logger\u0026#34;: \u0026#34;reconciler.scan job\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Scan job container\u0026#34;, \u0026#34;job\u0026#34;: \u0026#34;trivy-system/scan-vulnerabilityreport-7f665c795b\u0026#34;, \u0026#34;container\u0026#34;: \u0026#34;calico-windows-upgrade\u0026#34;, \u0026#34;status.reason\u0026#34;: \u0026#34;Error\u0026#34;, \u0026#34;status.message\u0026#34;: \u0026#34;2024-04-23T03:07:53.141Z\\t\\u001b[31mFATAL\\u001b[0m\\timage scan error: scan error: unable to initialize a scanner: unable to initialize an image scanner: 4 errors occurred:\\n\\t* docker error: unable to inspect the image (mcr.microsoft.com/oss/calico/windows-upgrade:v3.26.3): Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\\n\\t* containerd error: containerd socket not found: /run/containerd/containerd.sock\\n\\t* podman error: unable to initialize Podman client: no podman socket found: stat podman/podman.sock: no such file or directory\\n\\t* remote error: GET https://mcr.microsoft.com/v2/oss/calico/windows-upgrade/manifests/v3.26.3: MANIFEST_UNKNOWN: manifest tagged by \\\u0026#34;v3.26.3\\\u0026#34; is not found; map[Tag:v3.26.3]\\n\\n\\n\u0026#34;, \u0026#34;stacktrace\u0026#34;: \u0026#34;github.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).completedContainers\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:353\\ngithub.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).SetupWithManager.(*ScanJobController).reconcileJobs.func1\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:80\\nsigs.k8s.io/controller-runtime/pkg/reconcile.Func.Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.3/pkg/reconcile/reconcile.go:113\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.3/pkg/internal/controller/controller.go:119\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.3/pkg/internal/controller/controller.go:316\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.3/pkg/internal/controller/controller.go:266\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.3/pkg/internal/controller/controller.go:227\u0026#34; } I don\u0026rsquo;t need Windows upgrades at all, so I am thinking of options to handle this:\nDisable scanning with Trivy with label target workload (turn off DaemonSet-reports) namespace (turn off reports for all calico-system resources) Disable calico-windows-upgrade DaemonSet Don\u0026rsquo;t have a solution just yet. Didn\u0026rsquo;t prioritise this because triggers this error is a deprecated feature that will be removed in the future.\nScanning Windows images is not supported #Pretty self-explanatory.\n{ \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2024-04-08T10:07:35Z\u0026#34;, \u0026#34;logger\u0026#34;: \u0026#34;reconciler.scan job\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Scan job container\u0026#34;, \u0026#34;job\u0026#34;: \u0026#34;trivy-system/scan-vulnerabilityreport-7f4d674d74\u0026#34;, \u0026#34;container\u0026#34;: \u0026#34;init\u0026#34;, \u0026#34;status.reason\u0026#34;: \u0026#34;Error\u0026#34;, \u0026#34;status.message\u0026#34;: \u0026#34;Scanning Windows images is not supported.\u0026#34; } Scan job - OOMKilled âœ… #{ \u0026#34;level\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2024-04-08T10:08:16Z\u0026#34;, \u0026#34;logger\u0026#34;: \u0026#34;reconciler.scan job\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Scan job container\u0026#34;, \u0026#34;job\u0026#34;: \u0026#34;trivy-system/scan-vulnerabilityreport-5c498d8bc6\u0026#34;, \u0026#34;container\u0026#34;: \u0026#34;prometheus\u0026#34;, \u0026#34;status.reason\u0026#34;: \u0026#34;OOMKilled\u0026#34;, \u0026#34;status.message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;stacktrace\u0026#34;: \u0026#34;github.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).completedContainers\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:353\\ngithub.com/aquasecurity/trivy-operator/pkg/vulnerabilityreport/controller.(*ScanJobController).SetupWithManager.(*ScanJobController).reconcileJobs.func1\\n\\t/home/runner/work/trivy-operator/trivy-operator/pkg/vulnerabilityreport/controller/scanjob.go:80\\nsigs.k8s.io/controller-runtime/pkg/reconcile.Func.Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/reconcile/reconcile.go:113\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Reconcile\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:119\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).reconcileHandler\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:316\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).processNextWorkItem\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:266\\nsigs.k8s.io/controller-runtime/pkg/internal/controller.(*Controller).Start.func2.2\\n\\t/home/runner/go/pkg/mod/sigs.k8s.io/controller-runtime@v0.17.2/pkg/internal/controller/controller.go:227\u0026#34; } The default values for RAM wasn\u0026rsquo;t enough. We gave a little more request and limit for the scanners and this solved the problem. In addition there were 10 reports generated simultanuously. We changed it to 2 to give the nodes a little room. It is shown under spec.values in the manifest file.\nToo many requests #After a while, we started getting an error saying that we are sendign too many requests to the Trivy GitHub repo. I have some thought about why this might happen:\nSome images are retried every 15 min or so The cluster spins up jobs in which Trivy scans the same image every time the job runs 2024-10-03T07:31:26Z\tFATAL\tFatal error\tinit error: DB error: failed to download vulnerability DB: database download error: oci download error: failed to fetch the layer: GET https://ghcr.io/v2/aquasecurity/trivy-db/blobs/sha256:77a50f405854d311fdf062f2d7edf3c04c63e2f5d218751a29125431376757a1: TOOMANYREQUESTS: retry-after: 600.129Âµs, allowed: 44000/minute Possible solutions:\nDo not scan AKS. Maybe management would like an overview in case of a new Log4j? But then it should probably be in form of an SBOM. Which is probably generated after a scan Try to only scan the same image (with hash!!) once a day. Is it even possible? This would be a nice solution! Especially if standard applications are using the same images. Seems like this was a recently introduced bug. As discussed in this GitHub issue.\nResources # https://aquasecurity.github.io/trivy/v0.50/docs/target/kubernetes/ https://aquasecurity.github.io/trivy-operator/latest/ https://www.aquasec.com/blog/vulnerability-scanning-trivy-vs-the-trivy-operator/ https://github.com/aquasecurity/trivy/discussions/4905 https://github.com/aquasecurity/trivy/discussions/4499 https://aquasecurity.github.io/trivy/v0.17.2/private-registries/ K8s Lens: https://docs.k8slens.dev/ Lens extension: https://aquasecurity.github.io/trivy-operator/v0.10.1/tutorials/integrations/lens/ https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ https://github.com/aquasecurity/trivy-operator/issues/1659 ","date":null,"permalink":"/posts/trivy-operator/","section":"Blog posts","summary":"A step-by-step guide to setup the Trivy Operator in Kubernetes.","title":"Trivy in Kubernetes"},{"content":"","date":null,"permalink":"/tags/quality/","section":"Tags","summary":"","title":"Quality"},{"content":"I am currently working with automated security testing to get control of the known vulnerabilities in our applications. As part of this, I am scanning a Kubernetes cluster and it\u0026rsquo;s images, as well as application code. We want to cover the whole width, not only application code. Now, we look at a Infrastructure as Code (IaC) scanning tool, Trivy.\nNote! When it says \u0026ldquo;All-in-one\u0026rdquo; and \u0026ldquo;vulnerability scanning\u0026rdquo;, it does not mean application code scanning. The focus is on IaC, so find something else in addition for your application code!_ I am very happy with Trivy scanning. It is a nice free tool that is easy to use in GitHub, GitLab, locally, and just wherever you want.\nI am just hoping that this is not another Semgrep, a nice free tool that ends up as a paid tool after it becomes popular.\nAdvantages #There are many pitfalls when writing IaC, and scanning it helps us in several ways. We don\u0026rsquo;t need to know everything, and we don\u0026rsquo;t need to pay constant attention to new vulnerabilities. We get more control of what we create, and create more predictable applications. We can be more confident on what we deliver when we run scans like this.\nWhen \u0026amp; where to scan # At your local environment, before pushing to remote (VS Code extension, pre-commit hooks, etc.) As automatic PR review. Although, I only believe in using this as a quality gate as long as it is possible to buypass it. In case of critical scenarios, such as fixing down-time or a critical bug. Regularly in the production environment, e.g. every saturday evening. What scans to run #We should run different Trivy scans, and which will always differ from application to application. However, in general, I believe this scans should be run:\nConfiguration file scan, to scan your IaC configuration files for known vulnerabilities Secrets scan, to check if there are any secrets present in your code Dependency scan, to scan your dependency versions for known vulnerabilities Image scan, to scan images. In my opinion, this should be done both on PR review and regularly in prod. K8s cluster scan, if you have a K8s cluster, this is a super way to scan images in the Kubernets cluster when they appear. The three first scans can be done in Trivy filesystem scan, configuring it with `\u0026ndash;scanners=misconfig,secret,vuln. I would do both the filesystem scan and image scan as CI checks in a PR review.\nDockerfile scan vs image scan # Do we really need both? Yes! I asked my skilled colleagues this very questions, and can say that without doubt, you should do both!\nThis is section based on my colleague\u0026rsquo;s explanation.\nDockerfile scan checks the instructions used to build an image, such as the base image, package installations, config files and scripts. Also, whether you use best practices for versions, users with too high privileges or exposure of sensitive data, e.g. insecure mounting of fileshare.\nImage scanning finds known vulnerabilities in all installed packages, including the base image and dependencies that aren\u0026rsquo;t directly visible in the Dockerfiel. Image scanning gives more of a depth of all the packages and third-party dependencies. E.g. using an image that is running an old version of Python with known vulnerabilities won\u0026rsquo;t be found by the Dockerfile scan, but it will be discovered by the image scan. Only if the usage is explicitly written in the Dockerfile.\nStep-by-step guides for different scans #I am going to write different guides on applying Trivy in projects. Here are the ones I have so far:\nTrivy in Kubernetes Trivy in CI pipelines (coming soon) ","date":null,"permalink":"/posts/trivy/","section":"Blog posts","summary":"Contains several guides for applying Trivy to your project","title":"Trivy Infrastructure as Code (IaC) Scanning"},{"content":"","date":null,"permalink":"/tags/flux/","section":"Tags","summary":"","title":"Flux"},{"content":"\n1. Setup Kind cluster with local registry #Find the script in the post Kind Cluster with Local Registry\ncd ~/git/flux-image-updates/clusters ./create-kind-cluster-with-registry.sh 2. Run Flux #Following the Flux guide \u0026ldquo;Automate image updates to Git\u0026rdquo;, I setup everything as follows:\nStart by adding your GitHub credentials as environment variables. PAT token can be found at Settings\u0026gt; Developer Settings\u0026gt; Tokens (classic). It requires the repo scope.\nexport GITHUB_TOKEN=ghp_gCVsYEC... export GITHUB_USER=maritiren You can run this although you already have an existing GitHub repo for Flux (called flux-image-updates). This does not overwrite manifest files.\nflux bootstrap github \\ --components-extra=image-reflector-controller,image-automation-controller \\ --owner=$GITHUB_USER \\ --repository=flux-image-updates \\ --branch=main \\ --path=clusters/my-cluster \\ --read-write-key \\ --personal 3. Setup secrets for namespaces to fetch images #Add secret for the namespaces you use to fetch an image:\nk create secret docker-registry regcred --docker-server=\u0026#34;kind-registry:5000\u0026#34; --docker-username=myuser --docker-password=myuser -n my-api k create secret docker-registry regcred2 --docker-server=\u0026#34;kind-registry:5000\u0026#34; --docker-username=myuser --docker-password=myuser -n flux-system Watch the image repositories to see status:\nwatch flux get image repository --all-namespaces And then reconcile the image repositories:\nflux reconcile image repository my-api -n my-api flux reconcile image repository podinfo -n flux-system 4. Push image to local registry #docker tag 0ac97f5bbbb5 localhost:5001/my-api:1.0.0 docker push localhost:5001/my-api:1.0.0 podinfo: https://hub.docker.com/r/stefanprodan/podinfo\ndocker pull stefanprodan/podinfo 5. (optional) Check contents of registry #Flux should automatically deploy new images when they get a new tag (according to the tag policy). To verify what\u0026rsquo;s in the registry, you can curl it.\nâœ— curl -X GET http://localhost:5001/v2/_catalog {\u0026#34;repositories\u0026#34;:[\u0026#34;my-api\u0026#34;,\u0026#34;hello-app\u0026#34;,\u0026#34;podinfo\u0026#34;]} **strong text** âœ— curl -X GET http://localhost:5001/v2/podinfo/tags/list {\u0026#34;name\u0026#34;:\u0026#34;podinfo\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;5.0.7\u0026#34;,\u0026#34;5.0.3\u0026#34;,\u0026#34;5.0.5\u0026#34;,\u0026#34;5.0.0\u0026#34;,\u0026#34;5.0.4\u0026#34;,\u0026#34;5.0.6\u0026#34;]} Cleanup #Only delete the cluster:\nkind cluster delete --name \u0026#34;kind-kind\u0026#34; Deleting both the cluster and registry. (From https://github.com/piyushjajoo/kind-with-local-registry-and-ingress/blob/master/destroy.sh):\n#!/bin/sh set -o errexit # delete kind cluster echo \u0026#34;deleting kind cluster\u0026#34; kind delete cluster --name \u0026#34;kind-kind\u0026#34; # delete registry echo \u0026#34;deleting registry\u0026#34; docker rm -f $(docker ps -a | grep registry | awk -F \u0026#39; \u0026#39; \u0026#39;{print $1}\u0026#39;) Debugging # K8s can connect to local registry, but Flux can\u0026rsquo;t K8s can\u0026rsquo;t connect to local registry, but Flux can Completely recreate deployment K8s can connect to local registry, but Flux can\u0026rsquo;t # Solution: Use port 5000 in the Deployment manifest files and other places in K8s. Even thouhg the port of the registry is 5001. This was one of the first huge issues I got while setting this up. I used so many hours debugging this. I cannot provide a complete overview of the debugging as I didn\u0026rsquo;t take notes at that time. However, I remember what fixed access for Flux in the end.\nAt first, the problem was that it didn\u0026rsquo;t really connect to the local registry at all. At that point the error message was something like \u0026ldquo;Connection refused\u0026rdquo;, so I thought I was going towards the local registry but had some authentication problem. Turned out I wasn\u0026rsquo;t even sending requests to the registry. Sorry, I don\u0026rsquo;t have the answer to this case here, probably changed some ports or DNS name of some sorts.\nHaving the local registry receiving my requests, I started getting the error http: server gave HTTP response to HTTPS client.\nI tried a couple of things, on of them was to add credentials to the docker config file and restart dockerd. A simple mistake in the config was made, which in turn made dockerd go bananas. It restarted all the time, wouldn\u0026rsquo;t allow us to reset and we ended up allowing more restarts in order to roll back the changes. This didn\u0026rsquo;t solve anything either.\nThen in the end, it turned out the error was that we used port 5001, while Kubernetes was connecting to the registry using port 5000. In other words, the solution was to use port 5000 in the Deployment manifest files and otherwise in Kubernetes. We still aren\u0026rsquo;t quite sure why, but assume this is due to how we connected the registry container and the cluster using docker network connect. Otherwise, from the outside of the cluster, we reach the registry using localhost:5001. PRETTY DARN CONFUSING! Localhost here and localhost there, K8s DNS name here. Good luck understanding this!\nK8s can\u0026rsquo;t connect to local registry, but Flux can #There are many (or few - depending on how you see things) options on what could be wrong. Here are a couple of different things that might help with this issue:\nSolution: What worked for me was to change the containerd configs in the cluster startup script. Changing containerd configs # https://github.com/kubernetes-sigs/kind/issues/2604#issuecomment-1041314277 Remove the existing config line and add this instead, in the cluster startup script. This makes some parts of the Kind script unuseful (the part of setting containerd settings in each node). You might change this either in cluster-config.yaml or in the Kind startup script.\ncontainerdConfigPatches: - |- [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;kind-registry:5000\u0026#34;] endpoint = [\u0026#34;http://kind-registry:5000\u0026#34;] Enable this in the Docker deamon (probably requires restart of deamon) #This didn\u0026rsquo;t work really, but maybe? Maybe I didn\u0026rsquo;t do it properly. Didn\u0026rsquo;t work for me, though.\nâœ— sudo cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/docker/daemon.json { \u0026#34;insecure-registries\u0026#34;: [\u0026#34;localhost:5001\u0026#34;] } Set network connection with Docker #This should have been done in the script from Kind, but it was suggested as a solution.\ndocker network connect kind kind-registry Completely recreate a deployment #âœ— k delete deployment my-api -n my-api âœ— flux reconcile kustomization flux-system --with-source Resources # https://kind.sigs.k8s.io/docs/user/local-registry/ https://hackernoon.com/kubernetes-cluster-setup-with-a-local-registry-and-ingress-in-docker-using-kind https://stackoverflow.com/a/3175054 ","date":null,"permalink":"/posts/flux-kind-localregistry/","section":"Blog posts","summary":"A step-by-step guide for setting up Flux in a Kind cluster with a local registry for automatic updates of Docker images.","title":"Flux with Local Registry"},{"content":"","date":null,"permalink":"/tags/kind/","section":"Tags","summary":"","title":"Kind"},{"content":"","date":null,"permalink":"/tags/local-registry/","section":"Tags","summary":"","title":"Local Registry"},{"content":"Setting up a local registry for Kind clusters requires settings to be applied when creating the cluster. It should work to just run the script provided in the Kind docs.\nHowever, I also need it to work with Flux which did not work out of the box. Therefore, I\u0026rsquo;ve modified the script from the Kind docs to work with Flux. Honestly, I don\u0026rsquo;t remember exactly why, but it is in step 2 and it is related to the FQDN used by the cluster to access the registry.\nHere is the script:\n#!/bin/sh # from https://kind.sigs.k8s.io/docs/user/local-registry/ set -o errexit # 1. Create registry container unless it already exists reg_name=\u0026#39;kind-registry\u0026#39; reg_port=\u0026#39;5001\u0026#39; if [ \u0026#34;$(docker inspect -f \u0026#39;{{.State.Running}}\u0026#39; \u0026#34;${reg_name}\u0026#34; 2\u0026gt;/dev/null || true)\u0026#34; != \u0026#39;true\u0026#39; ]; then docker run \\ -d --restart=always -p \u0026#34;127.0.0.1:${reg_port}:5000\u0026#34; --network bridge --name \u0026#34;${reg_name}\u0026#34; \\ registry:2 fi # 2. Create kind cluster with containerd registry config dir enabled # TODO: kind will eventually enable this by default and this patch will # be unnecessary. # # See: # https://github.com/kubernetes-sigs/kind/issues/2875 # https://github.com/containerd/containerd/blob/main/docs/cri/config.md#registry-configuration # See: https://github.com/containerd/containerd/blob/main/docs/hosts.md # # Original: # [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] # config_path = \u0026#34;/etc/containerd/certs.d\u0026#34; # # Ingress config (for DefectDojo app): # https://kind.sigs.k8s.io/docs/user/ingress/#create-cluster cat \u0026lt;\u0026lt;EOF | kind create cluster --config=- kind: Cluster apiVersion: kind.x-k8s.io/v1alpha4 containerdConfigPatches: - |- [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors] [plugins.\u0026#34;io.containerd.grpc.v1.cri\u0026#34;.registry.mirrors.\u0026#34;kind-registry:5000\u0026#34;] endpoint = [\u0026#34;http://kind-registry:5000\u0026#34;] nodes: - role: control-plane kubeadmConfigPatches: - | kind: InitConfiguration nodeRegistration: kubeletExtraArgs: node-labels: \u0026#34;ingress-ready=true\u0026#34; extraPortMappings: - containerPort: 80 hostPort: 80 protocol: TCP - containerPort: 443 hostPort: 443 protocol: TCP EOF # 3. Add the registry config to the nodes # # This is necessary because localhost resolves to loopback addresses that are # network-namespace local. # In other words: localhost in the container is not localhost on the host. # # We want a consistent name that works from both ends, so we tell containerd to # alias localhost:${reg_port} to the registry container when pulling images REGISTRY_DIR=\u0026#34;/etc/containerd/certs.d/localhost:${reg_port}\u0026#34; for node in $(kind get nodes); do docker exec \u0026#34;${node}\u0026#34; mkdir -p \u0026#34;${REGISTRY_DIR}\u0026#34; cat \u0026lt;\u0026lt;EOF | docker exec -i \u0026#34;${node}\u0026#34; cp /dev/stdin \u0026#34;${REGISTRY_DIR}/hosts.toml\u0026#34; [host.\u0026#34;http://${reg_name}:5000\u0026#34;] EOF done # 4. Connect the registry to the cluster network if not already connected # This allows kind to bootstrap the network but ensures they\u0026#39;re on the same network if [ \u0026#34;$(docker inspect -f=\u0026#39;{{json .NetworkSettings.Networks.kind}}\u0026#39; \u0026#34;${reg_name}\u0026#34;)\u0026#34; = \u0026#39;null\u0026#39; ]; then docker network connect \u0026#34;kind\u0026#34; \u0026#34;${reg_name}\u0026#34; fi # 5. Document the local registry # https://github.com/kubernetes/enhancements/tree/master/keps/sig-cluster-lifecycle/generic/1755-communicating-a-local-registry cat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: ConfigMap metadata: name: local-registry-hosting namespace: kube-public data: localRegistryHosting.v1: | host: \u0026#34;localhost:${reg_port}\u0026#34; help: \u0026#34;https://kind.sigs.k8s.io/docs/user/local-registry/\u0026#34; EOF ","date":null,"permalink":"/posts/kind-localregistry/","section":"Blog posts","summary":"A script to set up Kind and a local registry, with containerd patches to make it work for Flux","title":"Kind with Local Registry for Flux"},{"content":" Blip blop ","date":"1 January 0001","permalink":"/about/","section":"Welcome to my notes! ðŸŽ‰","summary":"","title":"About the author"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"}]